# TopLogic AI Integration

AI integration for TopLogic applications with LLM support, MCP server capabilities, and chat functionality.

## Modules

### [tl-ai-service](tl-ai-service/)
AI service integration providing LLM access through LangChain4j with support for OpenAI, Anthropic, and Mistral models. Includes TL-Script functions for chat, structured JSON output, and multimodal content.

### [tl-ai-mcp-server](tl-ai-mcp-server/)
Model Context Protocol (MCP) server implementation enabling AI agents to interact with TopLogic's model structure, metadata, and business logic through standardized resources and tools.

### [tl-chat](tl-chat/)
Chat UI components and model definitions for building conversational interfaces within TopLogic applications.

### [tl-ai-demo](tl-ai-demo/)
Demo application showcasing AI integration features including chat interactions, MCP server capabilities, and AI-powered business logic.

## Quick Start

### Prerequisites
- Java 17+
- Maven 3.8+
- TopLogic 7.10.0-SNAPSHOT
- Optional: API keys for AI providers (OpenAI, Anthropic, or Mistral)

### Build

```bash
# Build all modules
mvn clean install
```

### Configuration

Set your API keys as environment variables:

```bash
export tl_openai_apikey="sk-..."
export tl_antropic_apikey="sk-ant-..."
export tl_mistral_apikey="..."
```

Configure AI models in `tl-ai-service/src/main/webapp/WEB-INF/conf/tl-ai-service.config.xml`.

### Run Demo

```bash
cd tl-ai-demo
mvn
```

Access at: http://localhost:8080/tl-ai-demo/
